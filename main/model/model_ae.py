# -*- coding: utf-8 -*-


# @Time  : 2020/1/14 下午4:23
# @Author : updbdipt
# @Project : CDW_FedAvg
# @FileName: model_ae


from abc import ABC, abstractmethod
import numpy as np
import tensorflow as tf


from main.utils.model_utils import batch_data
from main.utils.tf_utils import graph_size




class Model(ABC):


   def __init__(self, config, seed, lr, optimizer=None):
       self.lr = lr
       self.seed = seed
       self._optimizer = optimizer
       self.config = config
       self.graph = tf.Graph()
       with self.graph.as_default():
           tf.random.set_seed(123 + self.seed)
           # self.features, self.labels, self.train_op, self.eval_metric_ops, self.loss, self.tp_op, \
           # self.tn_op, self.fp_op, self.fn_op = self.create_model()
           self.features, self.encoder, self.train_op, self.loss = self.create_model()
           self.saver = tf.compat.v1.train.Saver()
       self.sess = tf.compat.v1.Session(graph=self.graph)


       self.size = graph_size(self.graph)


       with self.graph.as_default():
           self.sess.run(tf.compat.v1.global_variables_initializer())


           metadata = tf.compat.v1.RunMetadata()
           opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()
           self.flops = tf.compat.v1.profiler.profile(self.graph, run_meta=metadata, cmd='scope', options=opts).total_float_ops


       np.random.seed(self.seed)


   def set_params(self, model_params):
       with self.graph.as_default():
           all_vars = tf.trainable_variables()
           for variable, value in zip(all_vars, model_params):
               variable.load(value, self.sess)


   def get_params(self):
       with self.graph.as_default():
           model_params = self.sess.run(tf.trainable_variables())
       return model_params


   @property
   def optimizer(self):
       """Optimizer to be used by the model."""
       if self._optimizer is None:
           self._optimizer = tf.optimizers.SGD(learning_rate=self.lr)


       return self._optimizer


   @abstractmethod
   def create_model(self):
       """"Creates the model for the task.


       Returns:
           A 4-tuple consisting of:
               features: A placeholder for the samples' features.
               labels: A placeholder for the samples' labels.
               train_op: A Tensorflow operation that, when run with the features and
                   the labels, trains the model.
               eval_metric_ops: A Tensorflow operation that, when run with features and labels,
                   returns the accuracy of the model.
       """
       return None, None, None, None, None


   def train(self, data, num_epochs=1, batch_size=10):
       """
       Trains the client model.


       Args:
           data: Dict of the form {'x': [list], 'y': [list]}.
           num_epochs: Number of epochs to train.
           batch_size: Size of training batches.
       Return:
           comp: Number of FLOPs computed while training given data
           update: List of np.ndarray weights, with each weight array
               corresponding to a variable in the resulting graph
       """
       for _ in range(num_epochs):
           self.run_epoch(data, batch_size)


       update = self.get_params()
       comp = num_epochs * (len(data['y']) // batch_size) * batch_size * self.flops
       return comp, update


   def run_epoch(self, data, batch_size):


       for batched_x, batched_y in batch_data(data, batch_size, seed=self.seed):
           input_data = self.process_x(batched_x)
           target_data = self.process_y(batched_y)


           with self.graph.as_default():
               self._run(self.train_op,
                             feed_dict={
                                 self.features: input_data
                             })


   def test(self, data):
       """
       Tests the current model on the given data.


       Args:
           data: dict of the form {'x': [list], 'y': [list]}
       Return:
           dict of metrics that will be recorded by the simulation.
       """
       x_vecs = self.process_x(data['x'])
       labels = self.process_y(data['y'])
       with self.graph.as_default():


           encoder, loss = self.sess.run(
               [self.encoder, self.loss],
               feed_dict={self.features: x_vecs}
           )


       return encoder, {'loss': loss}


   def close(self):
       self.sess.close()


   @abstractmethod
   def process_x(self, raw_x_batch):
       """Pre-processes each batch of features before being fed to the model."""
       pass


   @abstractmethod
   def process_y(self, raw_y_batch):
       """Pre-processes each batch of labels before being fed to the model."""
       pass







